# Introduction

This article has a list of common interview questions and resources for finding answers.

# Questions

## What is tokenization, and why is it important in LLMs?

Tokenization is the process of splitting text into smaller units called token. For speed and performance reasons, LLMs are trained on the relationship between input tokens and output tokens to continue the sequence. 

Resources:
 - https://learn.microsoft.com/en-us/dotnet/ai/conceptual/understanding-tokens
 - https://huggingface.co/learn/llm-course/en/chapter2/4 

## Explain the concept of temperature in LLM text generation

Resources:
 - https://www.ibm.com/think/topics/llm-temperature

## How does prompting influence the output of a LLM?

Large language models are non deterministic systems. Small changes in the input text can produce varrying results.This input text, called a prompt may consist of user queries, relevant content, system instructions and other relevant information.

Resources:
 - https://huggingface.co/docs/transformers/v4.49.0/en/tasks/prompting