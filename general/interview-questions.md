# Introduction

This article has a list of common interview questions and resources for finding answers.

# Questions

## What is tokenization, and why is it important in LLMs?

Tokenization is the process of splitting text into smaller units called token. For speed and performance reasons, LLMs are trained on the relationship between input tokens and output tokens to continue the sequence. 

Resources:
 - https://learn.microsoft.com/en-us/dotnet/ai/conceptual/understanding-tokens
 - https://huggingface.co/learn/llm-course/en/chapter2/4 
